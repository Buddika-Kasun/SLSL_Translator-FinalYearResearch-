{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2c3f48",
   "metadata": {},
   "source": [
    "# ===============================================================\n",
    "# ğŸ“˜ NOTEBOOK 1: Dataset Creation\n",
    "# SLSL Sentence-Based Dataset Landmark Extraction Pipeline\n",
    "# Uses MediaPipe Holistic to extract hand, pose, and lip landmarks\n",
    "# Dataset is structured in Google Drive by sentence folders\n",
    "# ===============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84295355",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 1: Install Dependencies ---\n",
    "\n",
    "!pip install mediapipe opencv-python pandas numpy tqdm matplotlib\n",
    "!apt update && apt install -y ffmpeg\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Mount Google Drive ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… All dependencies installed and mounted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8da8c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 2: Folder Setup ---\n",
    "\n",
    "def create_sentence_based_structure():\n",
    "    \"\"\"Create necessary folders in Colab workspace\"\"\"\n",
    "    os.makedirs('/content/raw_videos', exist_ok=True)\n",
    "    os.makedirs('/content/landmarks_data', exist_ok=True)\n",
    "    os.makedirs('/content/metadata', exist_ok=True)\n",
    "    os.makedirs('/content/visualizations', exist_ok=True)\n",
    "    print(\"âœ… Folder structure ready!\")\n",
    "    print(\"ğŸ“ /content/raw_videos â€“ for input videos\")\n",
    "    print(\"ğŸ“ /content/landmarks_data â€“ for output .npy files\")\n",
    "    print(\"ğŸ“ /content/metadata â€“ for metadata and mapping files\")\n",
    "    print(\"ğŸ“ /content/visualizations â€“ for charts and analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a51a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3: Copy Dataset from Google Drive ---\n",
    "\n",
    "def copy_from_drive(drive_path='/content/drive/MyDrive/SLSL_Medical_Dataset'):\n",
    "    \"\"\"\n",
    "    Copy your structured folder from Google Drive into Colab.\n",
    "    Your Drive should have:\n",
    "      MyDrive/SLSL_Medical_Dataset/\n",
    "        â”œâ”€â”€ à¶¸à¶œà·™_à¶…à¶­à·š_à¶‹à¶«à·”à·ƒà·”à¶¸_à·€à·à¶©à·’/\n",
    "        â”‚   â”œâ”€â”€ signer_01_rep_01.mp4\n",
    "        â”‚   â””â”€â”€ ...\n",
    "        â”œâ”€â”€ à¶¸à¶œà·š_à¶…à¶­à·š_à¶­à·”à·€à·à¶½à¶ºà¶šà·Š_à¶­à·’à¶ºà·™à¶±à·€à·/\n",
    "        â”‚   â”œâ”€â”€ signer_01_rep_01.mp4\n",
    "        â”‚   â””â”€â”€ ...\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ğŸ“‚ Looking for dataset at: {drive_path}\")\n",
    "    \n",
    "    if os.path.exists(drive_path):\n",
    "        # Remove existing if any\n",
    "        if os.path.exists('/content/raw_videos'):\n",
    "            shutil.rmtree('/content/raw_videos')\n",
    "        \n",
    "        shutil.copytree(drive_path, '/content/raw_videos', dirs_exist_ok=True)\n",
    "        print(\"âœ… Copied entire structure from Google Drive!\")\n",
    "        \n",
    "        # Count and display structure\n",
    "        sentences = [f for f in os.listdir('/content/raw_videos') \n",
    "                    if os.path.isdir(os.path.join('/content/raw_videos', f))]\n",
    "        print(f\"ğŸ“ Found {len(sentences)} sentence folders:\")\n",
    "        \n",
    "        total_videos = 0\n",
    "        for sentence in sentences:\n",
    "            sentence_path = f\"/content/raw_videos/{sentence}\"\n",
    "            video_files = [f for f in os.listdir(sentence_path) \n",
    "                          if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "            total_videos += len(video_files)\n",
    "            print(f\"   ğŸ“‚ {sentence}: {len(video_files)} videos\")\n",
    "        \n",
    "        print(f\"\\nğŸ“Š TOTAL: {len(sentences)} sentences, {total_videos} videos\")\n",
    "        return sentences\n",
    "    else:\n",
    "        print(f\"âŒ Folder not found in Google Drive at: {drive_path}\")\n",
    "        print(\"ğŸ’¡ Available folders in MyDrive:\")\n",
    "        try:\n",
    "            print(os.listdir('/content/drive/MyDrive'))\n",
    "        except:\n",
    "            print(\"Could not list MyDrive contents\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dee3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 4: Setup MediaPipe Holistic ---\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def setup_mediapipe():\n",
    "    \"\"\"Setup MediaPipe Holistic with balanced accuracy/speed\"\"\"\n",
    "    holistic = mp_holistic.Holistic(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=1,  # 0=Lite, 1=Full, 2=Heavy\n",
    "        smooth_landmarks=True,\n",
    "        enable_segmentation=False,\n",
    "        refine_face_landmarks=True,  # Need this for lips\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    )\n",
    "    return holistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce8f28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 5: Extract Landmarks from Frame ---\n",
    "\n",
    "def extract_frame_landmarks(frame, holistic_model):\n",
    "    \"\"\"Extract hand, pose, and lip landmarks from one frame\"\"\"\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_rgb.flags.writeable = False\n",
    "    results = holistic_model.process(frame_rgb)\n",
    "\n",
    "    landmarks_dict = {\n",
    "        'left_hand': None,\n",
    "        'right_hand': None,\n",
    "        'pose': None,\n",
    "        'face': None,\n",
    "        'lip_roi': None,\n",
    "        'timestamp': None\n",
    "    }\n",
    "\n",
    "    # --- Left Hand (21 points Ã— 4 values) ---\n",
    "    if results.left_hand_landmarks:\n",
    "        left_hand = []\n",
    "        for landmark in results.left_hand_landmarks.landmark:\n",
    "            left_hand.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        landmarks_dict['left_hand'] = left_hand\n",
    "\n",
    "    # --- Right Hand (21 points Ã— 4 values) ---\n",
    "    if results.right_hand_landmarks:\n",
    "        right_hand = []\n",
    "        for landmark in results.right_hand_landmarks.landmark:\n",
    "            right_hand.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        landmarks_dict['right_hand'] = right_hand\n",
    "\n",
    "    # --- Pose Upper Body (first 25 points Ã— 4 values) ---\n",
    "    if results.pose_landmarks:\n",
    "        pose = []\n",
    "        upper_body_indices = list(range(25))  # Upper body only\n",
    "        for i in upper_body_indices:\n",
    "            landmark = results.pose_landmarks.landmark[i]\n",
    "            pose.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        landmarks_dict['pose'] = pose\n",
    "\n",
    "    # --- Face and Lips from Face Mesh ---\n",
    "    if results.face_landmarks:\n",
    "        # Key lip landmarks for speech reading\n",
    "        lip_indices = [\n",
    "            61, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "            78, 95, 88, 178, 87, 14, 317, 402, 318, 324,\n",
    "            308, 415, 310, 311, 312, 13, 82, 81, 80, 191,\n",
    "            78, 76, 74, 73, 70, 63, 62, 96, 89, 179,\n",
    "            86, 15, 316, 403, 319, 325, 307, 414, 309, 313\n",
    "        ]\n",
    "        \n",
    "        lip_landmarks = []\n",
    "        face_landmarks = []\n",
    "        \n",
    "        for i, landmark in enumerate(results.face_landmarks.landmark):\n",
    "            face_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "            if i in lip_indices:\n",
    "                lip_landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        \n",
    "        landmarks_dict['face'] = face_landmarks\n",
    "        landmarks_dict['lip_roi'] = lip_landmarks\n",
    "\n",
    "    return landmarks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ab9e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 6: Process a Single Video ---\n",
    "\n",
    "def process_single_video(video_path, holistic_model, target_frames=60):\n",
    "    \"\"\"Process one video and extract landmarks frame by frame\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_data = []\n",
    "    frame_count = 0\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"\\nğŸ“¹ Processing: {os.path.basename(video_path)}\")\n",
    "    print(f\"   Total frames: {total_frames}, Target: {target_frames}\")\n",
    "\n",
    "    with tqdm(total=min(total_frames, target_frames), desc=\"   Extracting\") as pbar:\n",
    "        while cap.isOpened() and len(frames_data) < target_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            landmarks = extract_frame_landmarks(frame, holistic_model)\n",
    "            landmarks['timestamp'] = frame_count / fps\n",
    "            frames_data.append(landmarks)\n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    # If we have fewer frames than target, pad with zeros\n",
    "    if len(frames_data) < target_frames:\n",
    "        print(f\"   âš ï¸ Only {len(frames_data)} frames, padding to {target_frames}\")\n",
    "        # Create a zero frame template\n",
    "        if frames_data:\n",
    "            zero_frame = {k: (np.zeros_like(v) if v is not None else None) \n",
    "                         for k, v in frames_data[0].items()}\n",
    "            while len(frames_data) < target_frames:\n",
    "                frames_data.append(zero_frame.copy())\n",
    "    \n",
    "    print(f\"   âœ… Extracted {len(frames_data)} frames\")\n",
    "    return frames_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de55a9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 7: Process Entire Dataset ---\n",
    "\n",
    "def process_sentence_based_dataset(raw_videos_root='/content/raw_videos',\n",
    "                                   output_folder='/content/landmarks_data',\n",
    "                                   target_frames=60,\n",
    "                                   test_mode=False):\n",
    "    \"\"\"Process all sentence folders in dataset\"\"\"\n",
    "    metadata = []\n",
    "    \n",
    "    # Initialize MediaPipe\n",
    "    holistic = setup_mediapipe()\n",
    "    print(\"âœ… MediaPipe Holistic initialized\")\n",
    "\n",
    "    print(\"ğŸ” Scanning for sentence folders...\")\n",
    "    sentence_folders = [f for f in os.listdir(raw_videos_root)\n",
    "                        if os.path.isdir(os.path.join(raw_videos_root, f))]\n",
    "    \n",
    "    if not sentence_folders:\n",
    "        print(\"âŒ No sentence folders found!\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"ğŸ“ Found {len(sentence_folders)} sentences.\")\n",
    "    \n",
    "    # Sort for consistency\n",
    "    sentence_folders.sort()\n",
    "    \n",
    "    for sentence_idx, sentence in enumerate(sentence_folders):\n",
    "        sentence_path = os.path.join(raw_videos_root, sentence)\n",
    "        video_files = [f for f in os.listdir(sentence_path)\n",
    "                       if f.endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "        \n",
    "        # Sort videos for consistency\n",
    "        video_files.sort()\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"ğŸ¬ Sentence {sentence_idx+1}/{len(sentence_folders)}: {sentence}\")\n",
    "        print(f\"   Videos: {len(video_files)}\")\n",
    "        \n",
    "        if test_mode:\n",
    "            video_files = video_files[:2]  # Take first 2 videos in test mode\n",
    "            print(\"âš™ï¸ TEST MODE: Only 2 videos per sentence\")\n",
    "        \n",
    "        for video_file in video_files:\n",
    "            video_path = os.path.join(sentence_path, video_file)\n",
    "            \n",
    "            # Parse filename (signer_XX_rep_XX)\n",
    "            filename_parts = video_file.replace('.mp4', '').replace('.mov', '').split('_')\n",
    "            \n",
    "            # Handle different naming patterns\n",
    "            if len(filename_parts) >= 4 and 'signer' in filename_parts[0].lower():\n",
    "                signer_id = filename_parts[1] if len(filename_parts) > 1 else \"unknown\"\n",
    "                rep_number = filename_parts[3] if len(filename_parts) > 3 else \"01\"\n",
    "            else:\n",
    "                # Fallback for simple names\n",
    "                signer_id = \"unknown\"\n",
    "                rep_number = \"01\"\n",
    "            \n",
    "            try:\n",
    "                # Process video\n",
    "                landmarks_seq = process_single_video(video_path, holistic, target_frames)\n",
    "                \n",
    "                if landmarks_seq and len(landmarks_seq) > 0:\n",
    "                    # Create safe filename (remove special characters)\n",
    "                    safe_sentence = sentence.replace(' ', '_').replace('/', '_')\n",
    "                    output_filename = f\"{safe_sentence}_signer_{signer_id}_rep_{rep_number}.npy\"\n",
    "                    output_path = os.path.join(output_folder, output_filename)\n",
    "                    \n",
    "                    # Save landmarks\n",
    "                    np.save(output_path, landmarks_seq)\n",
    "                    \n",
    "                    # Calculate coverage statistics\n",
    "                    left_hand_frames = sum(1 for f in landmarks_seq if f['left_hand'] is not None)\n",
    "                    right_hand_frames = sum(1 for f in landmarks_seq if f['right_hand'] is not None)\n",
    "                    lip_frames = sum(1 for f in landmarks_seq if f['lip_roi'] is not None)\n",
    "                    pose_frames = sum(1 for f in landmarks_seq if f['pose'] is not None)\n",
    "                    total_frames = len(landmarks_seq)\n",
    "                    \n",
    "                    metadata.append({\n",
    "                        'landmarks_file': output_filename,\n",
    "                        'sentence': sentence,\n",
    "                        'sentence_id': f\"S{str(sentence_idx+1).zfill(3)}\",\n",
    "                        'signer_id': signer_id,\n",
    "                        'rep_number': rep_number,\n",
    "                        'original_video': video_file,\n",
    "                        'total_frames': total_frames,\n",
    "                        'left_hand_frames': left_hand_frames,\n",
    "                        'right_hand_frames': right_hand_frames,\n",
    "                        'lip_frames': lip_frames,\n",
    "                        'pose_frames': pose_frames,\n",
    "                        'left_hand_coverage': (left_hand_frames / total_frames) * 100,\n",
    "                        'right_hand_coverage': (right_hand_frames / total_frames) * 100,\n",
    "                        'lip_coverage': (lip_frames / total_frames) * 100,\n",
    "                        'pose_coverage': (pose_frames / total_frames) * 100,\n",
    "                        'success': True\n",
    "                    })\n",
    "                    print(f\"   ğŸ’¾ Saved â†’ {output_filename}\")\n",
    "                else:\n",
    "                    print(f\"   âš ï¸ No landmarks in {video_file}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ Error processing {video_file}: {str(e)}\")\n",
    "                metadata.append({\n",
    "                    'landmarks_file': 'FAILED',\n",
    "                    'sentence': sentence,\n",
    "                    'signer_id': signer_id,\n",
    "                    'rep_number': rep_number,\n",
    "                    'original_video': video_file,\n",
    "                    'error': str(e),\n",
    "                    'success': False\n",
    "                })\n",
    "    \n",
    "    # Save metadata\n",
    "    if metadata:\n",
    "        metadata_df = pd.DataFrame(metadata)\n",
    "        meta_csv = '/content/metadata/sentence_dataset_metadata.csv'\n",
    "        metadata_df.to_csv(meta_csv, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        # Create sentence mapping\n",
    "        successful_df = metadata_df[metadata_df['success']]\n",
    "        sentence_mapping = {}\n",
    "        for idx, sentence in enumerate(successful_df['sentence'].unique()):\n",
    "            sentence_mapping[sentence] = f\"S{str(idx+1).zfill(3)}\"\n",
    "        \n",
    "        with open('/content/metadata/sentence_mapping.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(sentence_mapping, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Metadata saved â†’ {meta_csv}\")\n",
    "        print(f\"ğŸ“Š Sentence mapping saved â†’ /content/metadata/sentence_mapping.json\")\n",
    "        \n",
    "        return metadata_df, sentence_mapping\n",
    "    else:\n",
    "        print(\"âŒ No videos processed successfully!\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d8c49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 8: Dataset Analysis ---\n",
    "\n",
    "def analyze_sentence_dataset(metadata_df):\n",
    "    \"\"\"Print statistics about processed dataset\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š SENTENCE DATASET ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Filter successful\n",
    "    success_df = metadata_df[metadata_df['success']]\n",
    "    \n",
    "    total = len(metadata_df)\n",
    "    success = len(success_df)\n",
    "    print(f\"\\nğŸ“ˆ Overall Statistics:\")\n",
    "    print(f\"   Total videos: {total}\")\n",
    "    print(f\"   Successfully processed: {success} ({success/total*100:.1f}%)\")\n",
    "    print(f\"   Failed: {total - success} ({(total-success)/total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Sentences: {len(success_df['sentence'].unique())}\")\n",
    "    print(f\"ğŸ‘¥ Signers: {len(success_df['signer_id'].unique())}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Coverage Averages:\")\n",
    "    print(f\"   Left Hand:  {success_df['left_hand_coverage'].mean():.1f}%\")\n",
    "    print(f\"   Right Hand: {success_df['right_hand_coverage'].mean():.1f}%\")\n",
    "    print(f\"   Lips:       {success_df['lip_coverage'].mean():.1f}%\")\n",
    "    print(f\"   Pose:       {success_df['pose_coverage'].mean():.1f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ Videos per sentence:\")\n",
    "    sentence_stats = success_df['sentence'].value_counts()\n",
    "    for s, c in sentence_stats.items():\n",
    "        print(f\"   {s[:30]}{'...' if len(s)>30 else ''}: {c} videos\")\n",
    "    \n",
    "    print(f\"\\nğŸ‘¥ Videos per signer:\")\n",
    "    signer_stats = success_df['signer_id'].value_counts()\n",
    "    for s, c in signer_stats.items():\n",
    "        print(f\"   Signer {s}: {c} videos\")\n",
    "    \n",
    "    return success_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108eba0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 9: Visualize Coverage ---\n",
    "\n",
    "def visualize_coverage(metadata_df):\n",
    "    \"\"\"Visualize how well landmarks were detected\"\"\"\n",
    "    \n",
    "    success_df = metadata_df[metadata_df['success']]\n",
    "    \n",
    "    if len(success_df) == 0:\n",
    "        print(\"âŒ No successful videos to visualize\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Dataset Coverage Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Hand Coverage Histogram\n",
    "    axes[0,0].hist([success_df['left_hand_coverage'], \n",
    "                    success_df['right_hand_coverage']], \n",
    "                   bins=20, alpha=0.7, label=['Left Hand', 'Right Hand'])\n",
    "    axes[0,0].set_title('Hand Coverage Distribution')\n",
    "    axes[0,0].set_xlabel('Coverage %')\n",
    "    axes[0,0].set_ylabel('Number of Videos')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Lip Coverage\n",
    "    axes[0,1].hist(success_df['lip_coverage'], bins=20, color='red', alpha=0.7)\n",
    "    axes[0,1].set_title('Lip Coverage Distribution')\n",
    "    axes[0,1].set_xlabel('Coverage %')\n",
    "    axes[0,1].set_ylabel('Number of Videos')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Pose Coverage\n",
    "    axes[0,2].hist(success_df['pose_coverage'], bins=20, color='green', alpha=0.7)\n",
    "    axes[0,2].set_title('Pose Coverage Distribution')\n",
    "    axes[0,2].set_xlabel('Coverage %')\n",
    "    axes[0,2].set_ylabel('Number of Videos')\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Videos per Sentence\n",
    "    sentence_counts = success_df['sentence'].value_counts().head(10)\n",
    "    axes[1,0].barh(range(len(sentence_counts)), sentence_counts.values)\n",
    "    axes[1,0].set_yticks(range(len(sentence_counts)))\n",
    "    axes[1,0].set_yticklabels([s[:20] + '...' for s in sentence_counts.index])\n",
    "    axes[1,0].set_title('Top 10 Sentences by Video Count')\n",
    "    axes[1,0].set_xlabel('Number of Videos')\n",
    "    \n",
    "    # 5. Videos per Signer\n",
    "    signer_counts = success_df['signer_id'].value_counts()\n",
    "    axes[1,1].bar(signer_counts.index, signer_counts.values)\n",
    "    axes[1,1].set_title('Videos per Signer')\n",
    "    axes[1,1].set_xlabel('Signer ID')\n",
    "    axes[1,1].set_ylabel('Number of Videos')\n",
    "    \n",
    "    # 6. Success Rate Pie\n",
    "    success_count = len(success_df)\n",
    "    fail_count = len(metadata_df) - success_count\n",
    "    axes[1,2].pie([success_count, fail_count], \n",
    "                  labels=['Success', 'Failed'],\n",
    "                  autopct='%1.1f%%',\n",
    "                  colors=['green', 'red'])\n",
    "    axes[1,2].set_title('Processing Success Rate')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/visualizations/coverage_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ… Visualization saved to /content/visualizations/coverage_analysis.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61ed26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 10: Verify Landmark Files ---\n",
    "\n",
    "def verify_landmark_files(folder='/content/landmarks_data'):\n",
    "    \"\"\"Check a few saved .npy files\"\"\"\n",
    "    print(\"\\nğŸ” Verifying sample landmark files...\")\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.npy')]\n",
    "    \n",
    "    if not files:\n",
    "        print(\"âŒ No landmark files found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(files)} landmark files.\")\n",
    "    \n",
    "    for file in files[:3]:  # Check first 3\n",
    "        try:\n",
    "            data = np.load(os.path.join(folder, file), allow_pickle=True)\n",
    "            print(f\"\\nğŸ“„ {file}\")\n",
    "            print(f\"   Shape: {data.shape}\")\n",
    "            print(f\"   Frames: {len(data)}\")\n",
    "            if len(data) > 0:\n",
    "                print(f\"   Keys in first frame: {list(data[0].keys())}\")\n",
    "                \n",
    "                # Check data types\n",
    "                for key in ['left_hand', 'right_hand', 'lip_roi']:\n",
    "                    if data[0][key] is not None:\n",
    "                        print(f\"   {key} length: {len(data[0][key])}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error loading {file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b9d7be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 11: Export Dataset Summary ---\n",
    "\n",
    "def export_dataset_summary(metadata_df):\n",
    "    \"\"\"Export a human-readable summary\"\"\"\n",
    "    \n",
    "    success_df = metadata_df[metadata_df['success']]\n",
    "    \n",
    "    summary = {\n",
    "        'total_videos': len(metadata_df),\n",
    "        'successful_videos': len(success_df),\n",
    "        'failed_videos': len(metadata_df) - len(success_df),\n",
    "        'success_rate': f\"{len(success_df)/len(metadata_df)*100:.1f}%\",\n",
    "        'num_sentences': len(success_df['sentence'].unique()),\n",
    "        'num_signers': len(success_df['signer_id'].unique()),\n",
    "        'average_coverage': {\n",
    "            'left_hand': f\"{success_df['left_hand_coverage'].mean():.1f}%\",\n",
    "            'right_hand': f\"{success_df['right_hand_coverage'].mean():.1f}%\",\n",
    "            'lip': f\"{success_df['lip_coverage'].mean():.1f}%\",\n",
    "            'pose': f\"{success_df['pose_coverage'].mean():.1f}%\"\n",
    "        },\n",
    "        'sentences': {}\n",
    "    }\n",
    "    \n",
    "    # Add per-sentence details\n",
    "    for sentence in success_df['sentence'].unique():\n",
    "        sentence_videos = success_df[success_df['sentence'] == sentence]\n",
    "        summary['sentences'][sentence] = {\n",
    "            'video_count': len(sentence_videos),\n",
    "            'signers': list(sentence_videos['signer_id'].unique()),\n",
    "            'avg_left_hand': f\"{sentence_videos['left_hand_coverage'].mean():.1f}%\"\n",
    "        }\n",
    "    \n",
    "    # Save as JSON\n",
    "    with open('/content/metadata/dataset_summary.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Save as text report\n",
    "    with open('/content/metadata/dataset_report.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"SLSL MEDICAL DATASET REPORT\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Generated on: {pd.Timestamp.now()}\\n\\n\")\n",
    "        f.write(f\"Total Videos: {summary['total_videos']}\\n\")\n",
    "        f.write(f\"Successful: {summary['successful_videos']} ({summary['success_rate']})\\n\")\n",
    "        f.write(f\"Failed: {summary['failed_videos']}\\n\\n\")\n",
    "        f.write(f\"Number of Sentences: {summary['num_sentences']}\\n\")\n",
    "        f.write(f\"Number of Signers: {summary['num_signers']}\\n\\n\")\n",
    "        f.write(\"Average Coverage:\\n\")\n",
    "        for k, v in summary['average_coverage'].items():\n",
    "            f.write(f\"  {k}: {v}\\n\")\n",
    "    \n",
    "    print(\"âœ… Dataset summary exported to /content/metadata/\")\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba79b01",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 12: Main Pipeline ---\n",
    "\n",
    "def main_pipeline(test_mode=True):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸš€ SLSL SENTENCE-BASED DATASET PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Folder setup\n",
    "    print(\"\\nğŸ“ Step 1: Creating folders...\")\n",
    "    create_sentence_based_structure()\n",
    "    \n",
    "    # Step 2: Copy dataset from Google Drive\n",
    "    print(\"\\nğŸ“‚ Step 2: Copying dataset from Drive...\")\n",
    "    # !!! IMPORTANT: CHANGE THIS PATH TO MATCH YOUR FOLDER !!!\n",
    "    drive_path = '/content/drive/MyDrive/SLSL_Medical_Dataset'\n",
    "    sentences = copy_from_drive(drive_path=drive_path)\n",
    "    \n",
    "    if not sentences:\n",
    "        print(\"\\nâŒ No dataset found! Please check your Drive path.\")\n",
    "        print(\"Available folders in MyDrive:\")\n",
    "        !ls /content/drive/MyDrive/\n",
    "        return None, None\n",
    "    \n",
    "    # Step 3: Process dataset\n",
    "    print(\"\\nğŸ¯ Step 3: Processing videos...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    metadata_df, sentence_mapping = process_sentence_based_dataset(\n",
    "        test_mode=test_mode,\n",
    "        target_frames=60\n",
    "    )\n",
    "    \n",
    "    # Step 4: Analyze and verify\n",
    "    if metadata_df is not None and len(metadata_df) > 0:\n",
    "        print(\"\\nğŸ“Š Step 4: Analyzing results...\")\n",
    "        success_df = analyze_sentence_dataset(metadata_df)\n",
    "        \n",
    "        print(\"\\nğŸ” Step 5: Verifying landmark files...\")\n",
    "        verify_landmark_files()\n",
    "        \n",
    "        print(\"\\nğŸ“ˆ Step 6: Generating visualizations...\")\n",
    "        visualize_coverage(metadata_df)\n",
    "        \n",
    "        print(\"\\nğŸ“‹ Step 7: Exporting summary...\")\n",
    "        export_dataset_summary(metadata_df)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ‰ DATASET CREATION COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nâœ… Output files saved in:\")\n",
    "        print(\"   ğŸ“ /content/landmarks_data/ - Landmark .npy files\")\n",
    "        print(\"   ğŸ“ /content/metadata/ - CSV, JSON, and reports\")\n",
    "        print(\"   ğŸ“ /content/visualizations/ - Charts and graphs\")\n",
    "        \n",
    "        return metadata_df, sentence_mapping\n",
    "    else:\n",
    "        print(\"\\nâŒ Dataset creation failed. No videos processed.\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17ace6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 13: ZIP and Download Results ---\\\n",
    "\n",
    "def zip_and_download():\n",
    "    \"\"\"Zip all results for download\"\"\"\n",
    "    print(\"\\nğŸ“¦ Creating download package...\")\n",
    "    \n",
    "    # Create zip file\n",
    "    !zip -r /content/slsl_dataset_results.zip \\\n",
    "        /content/landmarks_data \\\n",
    "        /content/metadata \\\n",
    "        /content/visualizations\n",
    "    \n",
    "    print(\"âœ… Results zipped to: /content/slsl_dataset_results.zip\")\n",
    "    \n",
    "    # Download (will prompt in Colab)\n",
    "    from google.colab import files\n",
    "    files.download('/content/slsl_dataset_results.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac0aec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 14: RUN THE PIPELINE ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ READY TO RUN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Choose mode:\n",
    "# test_mode=True  : Process 2 videos per sentence (fast, for testing)\n",
    "# test_mode=False : Process ALL videos (full dataset)\n",
    "\n",
    "# For TESTING (recommended first):\n",
    "print(\"\\nğŸ”§ TEST MODE: Processing 2 videos per sentence\")\n",
    "metadata, mapping = main_pipeline(test_mode=True)\n",
    "\n",
    "# For FULL DATASET (uncomment when ready):\n",
    "# print(\"\\nğŸš€ FULL MODE: Processing ALL videos\")\n",
    "# metadata, mapping = main_pipeline(test_mode=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26f9da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 15: Check Results ---\n",
    "\n",
    "if metadata is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“‹ QUICK RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    success_df = metadata[metadata['success']]\n",
    "    print(f\"\\nâœ… Successfully processed: {len(success_df)} videos\")\n",
    "    print(f\"ğŸ“ Sentences: {len(success_df['sentence'].unique())}\")\n",
    "    print(f\"ğŸ‘¥ Signers: {len(success_df['signer_id'].unique())}\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š First 5 entries in metadata:\")\n",
    "    print(success_df[['sentence', 'signer_id', 'left_hand_coverage', \n",
    "                     'right_hand_coverage', 'lip_coverage']].head())\n",
    "else:\n",
    "    print(\"\\nâŒ No results to show. Run the pipeline first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a133e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 16: Download Results (Optional) ---\n",
    "\n",
    "# Uncomment the line below to download all results as a zip file\n",
    "# zip_and_download()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ END OF NOTEBOOK\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
