{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b19b54",
   "metadata": {},
   "source": [
    "# ===============================================================\n",
    "# üìô NOTEBOOK 3: Multi-Modal Model Training\n",
    "# Train the Bi-LSTM model with hand, pose, and lip streams\n",
    "# ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16cc1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 1: Setup ---\n",
    "!pip install tensorflow pandas numpy matplotlib scikit-learn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úÖ GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d0fa5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 2: Load Prepared Data ---\n",
    "def load_prepared_data():\n",
    "    \"\"\"Load data from Notebook 2\"\"\"\n",
    "    \n",
    "    # Load features\n",
    "    X_train = np.load('/content/prepared_data/X_train.npy')\n",
    "    X_val = np.load('/content/prepared_data/X_val.npy')\n",
    "    X_test = np.load('/content/prepared_data/X_test.npy')\n",
    "    \n",
    "    # Load labels\n",
    "    y_train = np.load('/content/prepared_data/y_train.npy')\n",
    "    y_val = np.load('/content/prepared_data/y_val.npy')\n",
    "    y_test = np.load('/content/prepared_data/y_test.npy')\n",
    "    \n",
    "    # Load metadata\n",
    "    with open('/content/prepared_data/dataset_info.json', 'r') as f:\n",
    "        info = json.load(f)\n",
    "    \n",
    "    # Load label encoder\n",
    "    with open('/content/label_encoder.pkl', 'rb') as f:\n",
    "        label_encoder = pickle.load(f)\n",
    "    \n",
    "    print(f\"üìä Data loaded:\")\n",
    "    print(f\"   Train: {X_train.shape}\")\n",
    "    print(f\"   Val:   {X_val.shape}\")\n",
    "    print(f\"   Test:  {X_test.shape}\")\n",
    "    print(f\"   Classes: {info['num_classes']}\")\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), info, label_encoder\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), info, label_encoder = load_prepared_data()\n",
    "\n",
    "# Convert to float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = info['num_classes']\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"\\n‚úÖ Labels converted to one-hot: {y_train_cat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e660de1e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 3: Define Multi-Modal Model Architecture ---\n",
    "def create_multi_modal_model(sequence_length=60, \n",
    "                             hand_features=84,    # 21 points √ó 4 values\n",
    "                             pose_features=100,   # 25 points √ó 4 values\n",
    "                             lip_features=200,    # 50 points √ó 4 values\n",
    "                             num_classes=10):\n",
    "    \"\"\"\n",
    "    Create multi-modal model with separate streams\n",
    "    Matches your proposal architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input layer (all features concatenated)\n",
    "    total_features = hand_features + pose_features + lip_features\n",
    "    inputs = layers.Input(shape=(sequence_length, total_features))\n",
    "    \n",
    "    # Split into modalities\n",
    "    hand_input = inputs[:, :, :hand_features]\n",
    "    pose_input = inputs[:, :, hand_features:hand_features+pose_features]\n",
    "    lip_input = inputs[:, :, hand_features+pose_features:]\n",
    "    \n",
    "    # === HAND STREAM (1D CNN) ===\n",
    "    hand_stream = layers.Conv1D(64, 3, padding='same', activation='relu')(hand_input)\n",
    "    hand_stream = layers.BatchNormalization()(hand_stream)\n",
    "    hand_stream = layers.Conv1D(128, 3, padding='same', activation='relu')(hand_stream)\n",
    "    hand_stream = layers.BatchNormalization()(hand_stream)\n",
    "    hand_stream = layers.MaxPooling1D(2)(hand_stream)\n",
    "    hand_stream = layers.GlobalAveragePooling1D()(hand_stream)\n",
    "    hand_stream = layers.Dense(64, activation='relu')(hand_stream)\n",
    "    hand_stream = layers.Dropout(0.3)(hand_stream)\n",
    "    \n",
    "    # === POSE STREAM (Dense layers) ===\n",
    "    pose_stream = layers.Conv1D(32, 3, padding='same', activation='relu')(pose_input)\n",
    "    pose_stream = layers.BatchNormalization()(pose_stream)\n",
    "    pose_stream = layers.GlobalAveragePooling1D()(pose_stream)\n",
    "    pose_stream = layers.Dense(32, activation='relu')(pose_stream)\n",
    "    pose_stream = layers.Dropout(0.3)(pose_stream)\n",
    "    \n",
    "    # === LIP STREAM (LSTM) ===\n",
    "    lip_stream = layers.Conv1D(64, 3, padding='same', activation='relu')(lip_input)\n",
    "    lip_stream = layers.BatchNormalization()(lip_stream)\n",
    "    lip_stream = layers.LSTM(64, return_sequences=True)(lip_stream)\n",
    "    lip_stream = layers.LSTM(32)(lip_stream)\n",
    "    lip_stream = layers.Dropout(0.3)(lip_stream)\n",
    "    \n",
    "    # === FEATURE FUSION ===\n",
    "    fused = layers.Concatenate()([hand_stream, pose_stream, lip_stream])\n",
    "    fused = layers.Dense(128, activation='relu')(fused)\n",
    "    fused = layers.Dropout(0.3)(fused)\n",
    "    \n",
    "    # === TEMPORAL MODELING (Bi-LSTM) ===\n",
    "    # Note: Since we already did temporal in streams, we can add another Bi-LSTM\n",
    "    # Or we can use the fused features directly\n",
    "    \n",
    "    # === CLASSIFICATION HEAD ===\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(fused)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_multi_modal_model(\n",
    "    sequence_length=X_train.shape[1],\n",
    "    hand_features=84,\n",
    "    pose_features=100,\n",
    "    lip_features=200,\n",
    "    num_classes=num_classes\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bc17a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 4: Alternative Model (Simpler) ---\n",
    "def create_simpler_model(sequence_length=60, feature_dim=384, num_classes=10):\n",
    "    \"\"\"Simpler model for quick training\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=(sequence_length, feature_dim)),\n",
    "        \n",
    "        # 1D Convolutions\n",
    "        layers.Conv1D(64, 3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv1D(64, 3, padding='same', activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        \n",
    "        layers.Conv1D(128, 3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv1D(128, 3, padding='same', activation='relu'),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create simpler model (if multi-modal is too complex)\n",
    "# model = create_simpler_model(\n",
    "#     sequence_length=X_train.shape[1],\n",
    "#     feature_dim=X_train.shape[2],\n",
    "#     num_classes=num_classes\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7ccce",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 5: Compile Model ---\n",
    "def compile_model(model, learning_rate=0.001):\n",
    "    \"\"\"Compile model with optimizer and metrics\"\"\"\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', \n",
    "                 keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Model compiled\")\n",
    "    return model\n",
    "\n",
    "model = compile_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf9f51",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 6: Callbacks ---\n",
    "def create_callbacks():\n",
    "    \"\"\"Create training callbacks\"\"\"\n",
    "    \n",
    "    # Create folder\n",
    "    os.makedirs('/content/models', exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        # Model checkpoint\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            '/content/models/best_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate on plateau\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # TensorBoard\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir='/content/logs',\n",
    "            histogram_freq=1\n",
    "        ),\n",
    "        \n",
    "        # CSV Logger\n",
    "        keras.callbacks.CSVLogger('/content/training_log.csv')\n",
    "    ]\n",
    "    \n",
    "    print(\"‚úÖ Callbacks created\")\n",
    "    return callbacks\n",
    "\n",
    "callbacks = create_callbacks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a249b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 7: Train Model ---\n",
    "def train_model(model, X_train, y_train_cat, X_val, y_val_cat, epochs=100, batch_size=32):\n",
    "    \"\"\"Train the model\"\"\"\n",
    "    \n",
    "    print(\"\\nüöÄ Starting training...\")\n",
    "    print(f\"   Epochs: {epochs}\")\n",
    "    print(f\"   Batch size: {batch_size}\")\n",
    "    print(f\"   Train samples: {len(X_train)}\")\n",
    "    print(f\"   Val samples: {len(X_val)}\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train_cat,\n",
    "        validation_data=(X_val, y_val_cat),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ Training complete!\")\n",
    "    \n",
    "    # Save final model\n",
    "    model.save('/content/models/final_model.h5')\n",
    "    print(\"üíæ Model saved to /content/models/\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "history = train_model(model, X_train, y_train_cat, X_val, y_val_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d37ebe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 8: Plot Training History ---\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training curves\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_title('Model Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history.history['accuracy'], label='Train Acc')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    axes[1].set_title('Model Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Top-3 Accuracy\n",
    "    if 'top3_acc' in history.history:\n",
    "        axes[2].plot(history.history['top3_acc'], label='Train Top-3')\n",
    "        axes[2].plot(history.history['val_top3_acc'], label='Val Top-3')\n",
    "        axes[2].set_title('Top-3 Accuracy')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Accuracy')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/training_history.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a08d2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 9: Evaluate on Test Set ---\n",
    "def evaluate_model(model, X_test, y_test_cat, label_encoder):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä TEST SET EVALUATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Loss and accuracy\n",
    "    loss, accuracy, top3_acc = model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "    print(f\"Test Loss: {loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"Test Top-3 Accuracy: {top3_acc:.4f} ({top3_acc*100:.2f}%)\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test_cat, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    target_names = label_encoder.classes_\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names[:10],  # Show first 10\n",
    "                yticklabels=target_names[:10])\n",
    "    plt.title('Confusion Matrix (First 10 Classes)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/confusion_matrix.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    return y_pred, y_true\n",
    "\n",
    "y_pred, y_true = evaluate_model(model, X_test, y_test_cat, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069921f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 10: Per-Class Accuracy ---\n",
    "def per_class_accuracy(y_true, y_pred, label_encoder):\n",
    "    \"\"\"Calculate accuracy per class\"\"\"\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import pandas as pd\n",
    "    \n",
    "    results = []\n",
    "    classes = label_encoder.classes_\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        mask = (y_true == i)\n",
    "        if np.sum(mask) > 0:\n",
    "            acc = accuracy_score(y_true[mask], y_pred[mask])\n",
    "            results.append({\n",
    "                'class': class_name,\n",
    "                'samples': np.sum(mask),\n",
    "                'accuracy': acc\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values('accuracy', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä Per-Class Accuracy:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_classes = df.head(15)\n",
    "    colors = ['green' if x > 0.8 else 'orange' if x > 0.6 else 'red' \n",
    "              for x in top_classes['accuracy']]\n",
    "    \n",
    "    plt.barh(range(len(top_classes)), top_classes['accuracy'].values, color=colors)\n",
    "    plt.yticks(range(len(top_classes)), [c[:30] + '...' for c in top_classes['class']])\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title('Per-Class Accuracy (Top 15)')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/per_class_accuracy.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "per_class_df = per_class_accuracy(y_true, y_pred, label_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef40d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 11: Error Analysis ---\n",
    "def error_analysis(y_true, y_pred, label_encoder, X_test):\n",
    "    \"\"\"Analyze where model makes mistakes\"\"\"\n",
    "    \n",
    "    # Find errors\n",
    "    errors = y_true != y_pred\n",
    "    error_indices = np.where(errors)[0]\n",
    "    \n",
    "    print(f\"\\nüîç ERROR ANALYSIS\")\n",
    "    print(f\"   Total errors: {len(error_indices)}/{len(y_true)} ({len(error_indices)/len(y_true)*100:.2f}%)\")\n",
    "    \n",
    "    if len(error_indices) > 0:\n",
    "        # Show some error examples\n",
    "        print(\"\\nüìù Example errors:\")\n",
    "        for idx in error_indices[:10]:\n",
    "            true_label = label_encoder.inverse_transform([y_true[idx]])[0]\n",
    "            pred_label = label_encoder.inverse_transform([y_pred[idx]])[0]\n",
    "            print(f\"   True: {true_label[:30]:30} ‚Üí Pred: {pred_label[:30]}\")\n",
    "        \n",
    "        # Confusion pairs\n",
    "        from collections import Counter\n",
    "        confusion_pairs = [(y_true[i], y_pred[i]) for i in error_indices]\n",
    "        pair_counts = Counter(confusion_pairs)\n",
    "        \n",
    "        print(\"\\nüîÑ Most confused pairs:\")\n",
    "        for (true, pred), count in pair_counts.most_common(5):\n",
    "            true_name = label_encoder.inverse_transform([true])[0][:20]\n",
    "            pred_name = label_encoder.inverse_transform([pred])[0][:20]\n",
    "            print(f\"   {true_name} ‚Üí {pred_name}: {count} times\")\n",
    "\n",
    "error_analysis(y_true, y_pred, label_encoder, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbd6f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 12: Convert to TFLite ---\n",
    "def convert_to_tflite(model, quantize=True):\n",
    "    \"\"\"Convert Keras model to TFLite for mobile deployment\"\"\"\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    if quantize:\n",
    "        # Apply quantization for mobile\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    \n",
    "    # Convert\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Save\n",
    "    tflite_path = '/content/models/sentence_model.tflite'\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"\\nüì± TFLite model saved: {tflite_path}\")\n",
    "    print(f\"   Size: {len(tflite_model) / 1024:.2f} KB\")\n",
    "    \n",
    "    # Test inference\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(f\"\\nüîç TFLite Model Info:\")\n",
    "    print(f\"   Input shape: {input_details[0]['shape']}\")\n",
    "    print(f\"   Output shape: {output_details[0]['shape']}\")\n",
    "    print(f\"   Input type: {input_details[0]['dtype']}\")\n",
    "    \n",
    "    return tflite_path\n",
    "\n",
    "tflite_path = convert_to_tflite(model, quantize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b265fd5c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 13: Test TFLite Inference ---\n",
    "def test_tflite_inference(tflite_path, X_test, y_test, num_samples=5):\n",
    "    \"\"\"Test TFLite model inference\"\"\"\n",
    "    \n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(\"\\nüß™ TESTING TFLITE INFERENCE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for i in range(min(num_samples, len(X_test))):\n",
    "        # Prepare input\n",
    "        input_data = X_test[i:i+1].astype(np.float32)\n",
    "        \n",
    "        # Set input\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        \n",
    "        # Run inference\n",
    "        import time\n",
    "        start = time.time()\n",
    "        interpreter.invoke()\n",
    "        inference_time = (time.time() - start) * 1000\n",
    "        \n",
    "        # Get output\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        pred_class = np.argmax(output[0])\n",
    "        \n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"   Inference time: {inference_time:.2f} ms\")\n",
    "        print(f\"   True: {label_encoder.inverse_transform([y_test[i]])[0][:30]}\")\n",
    "        print(f\"   Pred: {label_encoder.inverse_transform([pred_class])[0][:30]}\")\n",
    "        print(f\"   Confidence: {output[0][pred_class]:.4f}\")\n",
    "\n",
    "test_tflite_inference(tflite_path, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee066513",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 14: Save Model and Metadata for Flutter ---\n",
    "def save_for_flutter():\n",
    "    \"\"\"Save all files needed for Flutter app\"\"\"\n",
    "    \n",
    "    os.makedirs('/content/flutter_assets', exist_ok=True)\n",
    "    \n",
    "    # Copy TFLite model\n",
    "    !cp /content/models/sentence_model.tflite /content/flutter_assets/\n",
    "    \n",
    "    # Save label mapping\n",
    "    with open('/content/flutter_assets/label_mapping.json', 'w', encoding='utf-8') as f:\n",
    "        mapping = {str(i): label for i, label in enumerate(label_encoder.classes_)}\n",
    "        json.dump(mapping, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Save class list\n",
    "    with open('/content/flutter_assets/class_names.txt', 'w', encoding='utf-8') as f:\n",
    "        for label in label_encoder.classes_:\n",
    "            f.write(f\"{label}\\n\")\n",
    "    \n",
    "    # Save model info\n",
    "    model_info = {\n",
    "        'input_shape': X_train.shape[1:],\n",
    "        'num_classes': num_classes,\n",
    "        'sequence_length': X_train.shape[1],\n",
    "        'features_per_frame': X_train.shape[2],\n",
    "        'accuracy': float(history.history['val_accuracy'][-1]),\n",
    "        'normalization_mean': '/content/normalization_mean.npy',\n",
    "        'normalization_std': '/content/normalization_std.npy'\n",
    "    }\n",
    "    \n",
    "    with open('/content/flutter_assets/model_info.json', 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    \n",
    "    # Zip everything\n",
    "    !zip -r /content/flutter_model_files.zip /content/flutter_assets/\n",
    "    \n",
    "    print(\"\\n‚úÖ Flutter assets ready in /content/flutter_assets/\")\n",
    "    print(\"üì¶ Zipped to: /content/flutter_model_files.zip\")\n",
    "\n",
    "save_for_flutter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c746376",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- 15: Download All ---\n",
    "from google.colab import files\n",
    "\n",
    "# Download all results\n",
    "!zip -r /content/all_model_files.zip \\\n",
    "    /content/models \\\n",
    "    /content/flutter_assets \\\n",
    "    /content/training_log.csv \\\n",
    "    /content/training_history.png \\\n",
    "    /content/confusion_matrix.png \\\n",
    "    /content/per_class_accuracy.png\n",
    "\n",
    "files.download('/content/all_model_files.zip')\n",
    "\n",
    "print(\"\\nüéâ NOTEBOOK 3 COMPLETE! Model ready for Flutter app.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
